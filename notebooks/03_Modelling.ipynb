{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains an ALS model on the MovieLens 20M Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.get_data(\"/tmp/ml-20m/ratings.csv\")\n",
    "df = data.add_label(df).cache()\n",
    "\n",
    "train_df, valid_df, test_df = data.timesplit_data(df, train_dates=(\"2012-01-01\", \"2014-11-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+----------+\n",
      "|userId|movieId|rating|          timestamp|adj_rating|\n",
      "+------+-------+------+-------------------+----------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|       1.0|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|       1.0|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|       1.0|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|       1.0|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|       1.0|\n",
      "+------+-------+------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check date ranges in the train, valid and test splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+-------------------+\n",
      "|count(timestamp)|     min(timestamp)|     max(timestamp)|\n",
      "+----------------+-------------------+-------------------+\n",
      "|         1734812|2012-01-01 00:00:40|2014-10-31 23:59:26|\n",
      "+----------------+-------------------+-------------------+\n",
      "\n",
      "+----------------+-------------------+-------------------+\n",
      "|count(timestamp)|     min(timestamp)|     max(timestamp)|\n",
      "+----------------+-------------------+-------------------+\n",
      "|           79148|2014-11-01 00:01:36|2014-11-30 23:57:27|\n",
      "+----------------+-------------------+-------------------+\n",
      "\n",
      "+----------------+-------------------+-------------------+\n",
      "|count(timestamp)|     min(timestamp)|     max(timestamp)|\n",
      "+----------------+-------------------+-------------------+\n",
      "|           79644|2014-12-01 00:05:52|2014-12-31 23:49:53|\n",
      "+----------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df_split in [train_df, valid_df, test_df]:\n",
    "    df_split.selectExpr(\"count(timestamp)\", \"min(timestamp)\", \"max(timestamp)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify model hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 400\n",
    "maxIter = 20\n",
    "coldStartStrategy = \"drop\" # no difference if switch to \"nan\"!\n",
    "implicitPrefs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(rank=rank, \n",
    "          maxIter=maxIter,  \n",
    "          coldStartStrategy=coldStartStrategy, \n",
    "          implicitPrefs=implicitPrefs,\n",
    "          userCol=\"userId\", \n",
    "          itemCol=\"movieId\", \n",
    "          ratingCol=\"adj_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = als.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the validation set using the NDCG metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+----------+\n",
      "|userId|movieId|rating|          timestamp|adj_rating|\n",
      "+------+-------+------+-------------------+----------+\n",
      "|    96|    367|   2.0|2014-11-24 12:27:46|      -0.5|\n",
      "|    96|    527|   4.0|2014-11-24 12:26:45|       1.5|\n",
      "|    96|    608|   3.0|2014-11-24 12:27:26|       0.5|\n",
      "|    96|   1270|   4.5|2014-11-24 12:27:32|       2.0|\n",
      "|    96|   2011|   4.0|2014-11-24 12:28:24|       1.5|\n",
      "+------+-------+------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the predicted rankings for each user in the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_users = valid_df.select(\"userId\").distinct()\n",
    "predicted_ranks = model.recommendForUserSubset(valid_users, recsize)\n",
    "# predicted_ranks.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need the list of movies for each user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ranks = predicted_ranks \\\n",
    "    .rdd \\\n",
    "    .map(lambda r: (r.userId, [row.movieId for row in r.recommendations])) \\\n",
    "    .toDF([\"userId\", \"predicted_ranking\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the ground truth rankings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ranks = data.create_ground_truth_rankings(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how bad is the cold start problem for new users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_ranks \\\n",
    "#     .join(predicted_ranks, \"userId\", \"left\") \\\n",
    "#     .withColumn(\"missing_recs\", f.isnull(\"predicted_ranking\").cast(\"int\")) \\\n",
    "#     .selectExpr(\"count(missing_recs) AS total_users\",\n",
    "#                 \"sum(missing_recs) AS new_users\",\n",
    "#                 \"round(mean(missing_recs), 4) AS frac_users_with_missing_recs\") \\\n",
    "#     .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017735937566771254"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_and_labels = predicted_ranks \\\n",
    "    .join(actual_ranks, \"userId\", \"inner\") \\\n",
    "    .drop(\"userId\") \\\n",
    "    .rdd\n",
    "\n",
    "metrics = RankingMetrics(prediction_and_labels)\n",
    "\n",
    "metrics.ndcgAt(recsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013687600644122382"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precisionAt(recsize)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "dbconnect",
   "language": "python",
   "name": "dbconnect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
